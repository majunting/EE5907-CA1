{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "import timeit\n",
    "from datetime import timedelta\n",
    "from pathlib import Path\n",
    "import datetime as dt \n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from scipy.io import loadmat\n",
    "\n",
    "mat = loadmat('spamData.mat')  # load mat-file\n",
    "# mat = loadmat('../input/spamdata/spamData.mat')\n",
    "# sorted(mat.keys())\n",
    "x_test = mat['Xtest']  # variable in mat file\n",
    "x_train = mat['Xtrain']  # variable in mat file\n",
    "y_test = mat['ytest']  # variable in mat file\n",
    "y_train = mat['ytrain']  # variable in mat file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing: binarization and log transformation\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def logTrans(data):\n",
    "    return np.log(data + 0.1)\n",
    "\n",
    "xtrain = preprocessing.binarize(x_train)\n",
    "xtest = preprocessing.binarize(x_test)\n",
    "ytrain = y_train.flatten()\n",
    "ytest = y_test.flatten()\n",
    "xtest_log = logTrans(x_test)\n",
    "xtrain_log = logTrans(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1240 3065 0.40456769983686786\n"
     ]
    }
   ],
   "source": [
    "# let N1 be # of spam emails, N be total # of emails\n",
    "N1train = 0\n",
    "Ntrain = 0\n",
    "for row in y_train:\n",
    "#     print (row)\n",
    "    if row == 1:\n",
    "        N1train += 1\n",
    "    Ntrain += 1\n",
    "N0train = Ntrain - N1train\n",
    "print (N1train, Ntrain, N1train/Ntrain)\n",
    "MLE = np.log(N1train / Ntrain)\n",
    "MLE_neg = np.log(1-N1train/Ntrain)\n",
    "\n",
    "# # feature likelihood from training data\n",
    "# feature_likelihood = np.mean(xtrain[ytrain == 1], axis = 0)\n",
    "# print (feature_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_x_train(spammed):\n",
    "    return np.sum(xtrain[ytrain == spammed], axis = 0).astype('uint16')\n",
    "def sum_y_train(spammed):\n",
    "    return len(ytrain[ytrain == spammed])\n",
    "def posterior_predictive_distribution (spammed, alpha):\n",
    "    return ((sum_x_train(spammed)+alpha)/(sum_y_train(spammed)+2*alpha))\n",
    "def classify(email, alpha):\n",
    "    feature_count = len(email)\n",
    "    \n",
    "    param_spam = 0\n",
    "    param_non_spam = 0\n",
    "    \n",
    "    for i in np.arange(feature_count):\n",
    "        temp_post_dist_0 = posterior_predictive_distribution(0, alpha)[i]\n",
    "        temp_post_dist_1 = posterior_predictive_distribution(1, alpha)[i]\n",
    "        param_spam += (email[i] == 1) * np.log(temp_post_dist_1) + \\\n",
    "        (email[i] == 0) * np.log(1-temp_post_dist_1)\n",
    "        param_non_spam += (email[i] == 1) * np.log(temp_post_dist_0) + \\\n",
    "        (email[i] == 0) * np.log(1-temp_post_dist_0)\n",
    "        \n",
    "    prob_spam = MLE + param_spam\n",
    "    prob_non_spam = MLE_neg + param_non_spam\n",
    "\n",
    "    return (prob_spam > prob_non_spam).astype('uint8')\n",
    "def calc_error_rate_test(alpha):\n",
    "    error_count = 0\n",
    "    for count, email in enumerate(xtest):\n",
    "        if (classify(email, alpha) != ytest[count]):\n",
    "            error_count += 1\n",
    "    return error_count/len(xtest)\n",
    "def calc_error_rate_train(alpha):\n",
    "    error_count = 0\n",
    "    for count, email in enumerate(xtrain):\n",
    "        if (classify(email, alpha) != ytrain[count]):\n",
    "            error_count += 1\n",
    "    return error_count/len(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: divide by zero encountered in log\n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in multiply\n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:19: RuntimeWarning: divide by zero encountered in log\n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.0 computed\n",
      "alpha =  0.5 computed\n",
      "alpha =  1.0 computed\n",
      "alpha =  1.5 computed\n",
      "alpha =  2.0 computed\n",
      "alpha =  2.5 computed\n",
      "alpha =  3.0 computed\n",
      "alpha =  3.5 computed\n",
      "alpha =  4.0 computed\n",
      "alpha =  4.5 computed\n",
      "alpha =  5.0 computed\n",
      "alpha =  5.5 computed\n",
      "alpha =  6.0 computed\n",
      "alpha =  6.5 computed\n",
      "alpha =  7.0 computed\n",
      "alpha =  7.5 computed\n",
      "alpha =  8.0 computed\n",
      "alpha =  8.5 computed\n",
      "alpha =  9.0 computed\n",
      "alpha =  9.5 computed\n",
      "alpha =  10.0 computed\n",
      "alpha =  10.5 computed\n",
      "alpha =  11.0 computed\n",
      "alpha =  11.5 computed\n",
      "alpha =  12.0 computed\n",
      "alpha =  12.5 computed\n",
      "alpha =  13.0 computed\n",
      "alpha =  13.5 computed\n",
      "alpha =  14.0 computed\n",
      "alpha =  14.5 computed\n",
      "alpha =  15.0 computed\n",
      "alpha =  15.5 computed\n",
      "alpha =  16.0 computed\n",
      "alpha =  16.5 computed\n",
      "alpha =  17.0 computed\n",
      "alpha =  17.5 computed\n",
      "alpha =  18.0 computed\n",
      "alpha =  18.5 computed\n",
      "alpha =  19.0 computed\n",
      "alpha =  19.5 computed\n",
      "alpha =  20.0 computed\n",
      "alpha =  20.5 computed\n",
      "alpha =  21.0 computed\n",
      "alpha =  21.5 computed\n",
      "alpha =  22.0 computed\n",
      "alpha =  22.5 computed\n",
      "alpha =  23.0 computed\n",
      "alpha =  23.5 computed\n",
      "alpha =  24.0 computed\n",
      "alpha =  24.5 computed\n",
      "alpha =  25.0 computed\n",
      "alpha =  25.5 computed\n",
      "alpha =  26.0 computed\n",
      "alpha =  26.5 computed\n",
      "alpha =  27.0 computed\n",
      "alpha =  27.5 computed\n",
      "alpha =  28.0 computed\n",
      "alpha =  28.5 computed\n",
      "alpha =  29.0 computed\n",
      "alpha =  29.5 computed\n",
      "alpha =  30.0 computed\n",
      "alpha =  30.5 computed\n",
      "alpha =  31.0 computed\n",
      "alpha =  31.5 computed\n",
      "alpha =  32.0 computed\n",
      "alpha =  32.5 computed\n",
      "alpha =  33.0 computed\n",
      "alpha =  33.5 computed\n",
      "alpha =  34.0 computed\n",
      "alpha =  34.5 computed\n",
      "alpha =  35.0 computed\n",
      "alpha =  35.5 computed\n",
      "alpha =  36.0 computed\n",
      "alpha =  36.5 computed\n",
      "alpha =  37.0 computed\n",
      "alpha =  37.5 computed\n",
      "alpha =  38.0 computed\n",
      "alpha =  38.5 computed\n",
      "alpha =  39.0 computed\n",
      "alpha =  39.5 computed\n",
      "alpha =  40.0 computed\n",
      "alpha =  40.5 computed\n",
      "alpha =  41.0 computed\n",
      "alpha =  41.5 computed\n",
      "alpha =  42.0 computed\n",
      "alpha =  42.5 computed\n",
      "alpha =  43.0 computed\n",
      "alpha =  43.5 computed\n",
      "alpha =  44.0 computed\n",
      "alpha =  44.5 computed\n",
      "alpha =  45.0 computed\n",
      "alpha =  45.5 computed\n",
      "alpha =  46.0 computed\n",
      "alpha =  46.5 computed\n",
      "alpha =  47.0 computed\n",
      "alpha =  47.5 computed\n",
      "alpha =  48.0 computed\n",
      "alpha =  48.5 computed\n",
      "alpha =  49.0 computed\n",
      "alpha =  49.5 computed\n",
      "alpha =  50.0 computed\n",
      "alpha =  50.5 computed\n",
      "alpha =  51.0 computed\n",
      "alpha =  51.5 computed\n",
      "alpha =  52.0 computed\n",
      "alpha =  52.5 computed\n",
      "alpha =  53.0 computed\n",
      "alpha =  53.5 computed\n",
      "alpha =  54.0 computed\n",
      "alpha =  54.5 computed\n",
      "alpha =  55.0 computed\n",
      "alpha =  55.5 computed\n",
      "alpha =  56.0 computed\n",
      "alpha =  56.5 computed\n",
      "alpha =  57.0 computed\n",
      "alpha =  57.5 computed\n",
      "alpha =  58.0 computed\n",
      "alpha =  58.5 computed\n",
      "alpha =  59.0 computed\n",
      "alpha =  59.5 computed\n",
      "alpha =  60.0 computed\n",
      "alpha =  60.5 computed\n",
      "alpha =  61.0 computed\n",
      "alpha =  61.5 computed\n",
      "alpha =  62.0 computed\n",
      "alpha =  62.5 computed\n",
      "alpha =  63.0 computed\n",
      "alpha =  63.5 computed\n",
      "alpha =  64.0 computed\n",
      "alpha =  64.5 computed\n",
      "alpha =  65.0 computed\n",
      "alpha =  65.5 computed\n",
      "alpha =  66.0 computed\n",
      "alpha =  66.5 computed\n",
      "alpha =  67.0 computed\n",
      "alpha =  67.5 computed\n",
      "alpha =  68.0 computed\n",
      "alpha =  68.5 computed\n",
      "alpha =  69.0 computed\n",
      "alpha =  69.5 computed\n",
      "alpha =  70.0 computed\n",
      "alpha =  70.5 computed\n",
      "alpha =  71.0 computed\n",
      "alpha =  71.5 computed\n",
      "alpha =  72.0 computed\n",
      "alpha =  72.5 computed\n",
      "alpha =  73.0 computed\n",
      "alpha =  73.5 computed\n",
      "alpha =  74.0 computed\n",
      "alpha =  74.5 computed\n",
      "alpha =  75.0 computed\n",
      "alpha =  75.5 computed\n",
      "alpha =  76.0 computed\n",
      "alpha =  76.5 computed\n",
      "alpha =  77.0 computed\n",
      "alpha =  77.5 computed\n",
      "alpha =  78.0 computed\n",
      "alpha =  78.5 computed\n",
      "alpha =  79.0 computed\n",
      "alpha =  79.5 computed\n",
      "alpha =  80.0 computed\n",
      "alpha =  80.5 computed\n",
      "alpha =  81.0 computed\n",
      "alpha =  81.5 computed\n",
      "alpha =  82.0 computed\n",
      "alpha =  82.5 computed\n",
      "alpha =  83.0 computed\n",
      "alpha =  83.5 computed\n",
      "alpha =  84.0 computed\n",
      "alpha =  84.5 computed\n",
      "alpha =  85.0 computed\n",
      "alpha =  85.5 computed\n",
      "alpha =  86.0 computed\n",
      "alpha =  86.5 computed\n",
      "alpha =  87.0 computed\n",
      "alpha =  87.5 computed\n",
      "alpha =  88.0 computed\n",
      "alpha =  88.5 computed\n",
      "alpha =  89.0 computed\n",
      "alpha =  89.5 computed\n",
      "alpha =  90.0 computed\n",
      "alpha =  90.5 computed\n",
      "alpha =  91.0 computed\n",
      "alpha =  91.5 computed\n",
      "alpha =  92.0 computed\n",
      "alpha =  92.5 computed\n",
      "alpha =  93.0 computed\n",
      "alpha =  93.5 computed\n",
      "alpha =  94.0 computed\n",
      "alpha =  94.5 computed\n",
      "alpha =  95.0 computed\n",
      "alpha =  95.5 computed\n",
      "alpha =  96.0 computed\n",
      "alpha =  96.5 computed\n",
      "alpha =  97.0 computed\n",
      "alpha =  97.5 computed\n",
      "alpha =  98.0 computed\n",
      "alpha =  98.5 computed\n",
      "alpha =  99.0 computed\n",
      "alpha =  99.5 computed\n",
      "alpha =  100.0 computed\n",
      "[0.373046875, 0.12174479166666667, 0.12369791666666667, 0.12434895833333333, 0.125, 0.12565104166666666, 0.12565104166666666, 0.126953125, 0.12630208333333334, 0.12630208333333334, 0.126953125, 0.12565104166666666, 0.12565104166666666, 0.12565104166666666, 0.12565104166666666, 0.12565104166666666, 0.12565104166666666, 0.12565104166666666, 0.126953125, 0.126953125, 0.126953125, 0.12760416666666666, 0.12760416666666666, 0.12760416666666666, 0.12760416666666666, 0.12760416666666666, 0.12825520833333334, 0.12825520833333334, 0.12825520833333334, 0.12825520833333334, 0.12825520833333334, 0.12825520833333334, 0.12825520833333334, 0.12825520833333334, 0.12890625, 0.12955729166666666, 0.12955729166666666, 0.12955729166666666, 0.13020833333333334, 0.13216145833333334, 0.13216145833333334, 0.13216145833333334, 0.1328125, 0.13346354166666666, 0.13346354166666666, 0.13346354166666666, 0.1328125, 0.13346354166666666, 0.13346354166666666, 0.13346354166666666, 0.13346354166666666, 0.13346354166666666, 0.1328125, 0.13346354166666666, 0.13346354166666666, 0.13346354166666666, 0.13346354166666666, 0.13346354166666666, 0.13346354166666666, 0.1328125, 0.1328125, 0.1328125, 0.13346354166666666, 0.13346354166666666, 0.13346354166666666, 0.13346354166666666, 0.13346354166666666, 0.13346354166666666, 0.13411458333333334, 0.13411458333333334, 0.13411458333333334, 0.13411458333333334, 0.13411458333333334, 0.13541666666666666, 0.13541666666666666, 0.13606770833333334, 0.13606770833333334, 0.13606770833333334, 0.13606770833333334, 0.13606770833333334, 0.13606770833333334, 0.13606770833333334, 0.13671875, 0.13671875, 0.13671875, 0.13671875, 0.13671875, 0.13671875, 0.13671875, 0.13671875, 0.13671875, 0.13671875, 0.13736979166666666, 0.13736979166666666, 0.13736979166666666, 0.13736979166666666, 0.13736979166666666, 0.13736979166666666, 0.13736979166666666, 0.13736979166666666, 0.13736979166666666, 0.13736979166666666, 0.13802083333333334, 0.138671875, 0.13932291666666666, 0.13932291666666666, 0.13932291666666666, 0.13932291666666666, 0.13932291666666666, 0.13932291666666666, 0.13932291666666666, 0.13932291666666666, 0.13997395833333334, 0.13997395833333334, 0.13997395833333334, 0.13997395833333334, 0.13997395833333334, 0.13997395833333334, 0.13997395833333334, 0.13997395833333334, 0.13997395833333334, 0.13997395833333334, 0.13997395833333334, 0.13997395833333334, 0.13997395833333334, 0.140625, 0.140625, 0.140625, 0.140625, 0.140625, 0.140625, 0.140625, 0.14192708333333334, 0.14192708333333334, 0.14192708333333334, 0.14192708333333334, 0.14192708333333334, 0.142578125, 0.142578125, 0.142578125, 0.142578125, 0.142578125, 0.142578125, 0.142578125, 0.142578125, 0.14713541666666666, 0.14713541666666666, 0.14713541666666666, 0.14713541666666666, 0.14713541666666666, 0.146484375, 0.146484375, 0.146484375, 0.146484375, 0.146484375, 0.146484375, 0.146484375, 0.146484375, 0.14583333333333334, 0.14583333333333334, 0.14583333333333334, 0.14583333333333334, 0.14583333333333334, 0.14583333333333334, 0.14583333333333334, 0.14583333333333334, 0.14583333333333334, 0.14583333333333334, 0.14583333333333334, 0.14518229166666666, 0.14518229166666666, 0.14518229166666666, 0.14518229166666666, 0.14518229166666666, 0.14583333333333334, 0.146484375, 0.146484375, 0.146484375, 0.146484375, 0.14713541666666666, 0.14713541666666666, 0.14713541666666666, 0.146484375, 0.14713541666666666, 0.14713541666666666, 0.14713541666666666, 0.14713541666666666, 0.14713541666666666, 0.14713541666666666, 0.14713541666666666, 0.14713541666666666, 0.14713541666666666, 0.14713541666666666, 0.14713541666666666, 0.14713541666666666, 0.14713541666666666, 0.14713541666666666, 0.14713541666666666, 0.146484375, 0.146484375, 0.146484375]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-1607a9c6a242>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;32min\u001b[0m \u001b[0malphas\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0merror_rate_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcalc_error_rate_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"alpha = \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"computed\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0merror_rate_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-356d6eb238f6>\u001b[0m in \u001b[0;36mcalc_error_rate_train\u001b[1;34m(alpha)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0merror_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memail\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mclassify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memail\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m             \u001b[0merror_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0merror_count\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-356d6eb238f6>\u001b[0m in \u001b[0;36mclassify\u001b[1;34m(email, alpha)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mtemp_post_dist_0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mposterior_predictive_distribution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mtemp_post_dist_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mposterior_predictive_distribution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mparam_spam\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0memail\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_post_dist_1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-356d6eb238f6>\u001b[0m in \u001b[0;36mposterior_predictive_distribution\u001b[1;34m(spammed, alpha)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mytrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mytrain\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mspammed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mposterior_predictive_distribution\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mspammed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum_x_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspammed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum_y_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspammed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mclassify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memail\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mfeature_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memail\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-356d6eb238f6>\u001b[0m in \u001b[0;36msum_x_train\u001b[1;34m(spammed)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msum_x_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspammed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mytrain\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mspammed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'uint16'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msum_y_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspammed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mytrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mytrain\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mspammed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mposterior_predictive_distribution\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mspammed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# compute error rate for test data with different alpha values\n",
    "alphas = np.arange(0,100.5,0.5)\n",
    "error_rate_test = []\n",
    "error_rate_train = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    error_rate_test.append(calc_error_rate_test(alpha))\n",
    "    print (\"alpha = \", alpha, \"computed\")\n",
    "print (error_rate_test)\n",
    "\n",
    "for alpha in alphas:\n",
    "    error_rate_train.append(calc_error_rate_train(alpha))\n",
    "    print (\"alpha = \", alpha, \"computed\")\n",
    "print (error_rate_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2 Gaussian Naive Bayes\n",
    "\n",
    "# compute mean and standard deviation for ML estimation\n",
    "xtrain_log_mean_spam = np.mean(xtrain_log[ytrain == 1], axis = 0)\n",
    "xtrain_log_std_spam = np.std(xtrain_log[ytrain == 1], axis = 0)\n",
    "xtrain_log_mean_nonspam = np.mean(xtrain_log[ytrain == 0], axis = 0)\n",
    "xtrain_log_std_nonspam = np.std(xtrain_log[ytrain == 0], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_gaussian(email):\n",
    "    feature_count = len(email)\n",
    "    \n",
    "    param_spam = 0\n",
    "    param_non_spam = 0\n",
    "    \n",
    "    for i in np.arange(feature_count):\n",
    "        param_spam += -np.log(xtrain_log_std_spam[i]) - ((email[i] - xtrain_log_mean_spam[i])/(xtrain_log_std_spam[i])) ** 2 / 2\n",
    "        param_non_spam += -np.log(xtrain_log_std_nonspam[i]) - ((email[i] - xtrain_log_mean_nonspam[i])/(xtrain_log_std_nonspam[i])) ** 2 / 2\n",
    "        \n",
    "    prob_spam = MLE + param_spam\n",
    "    prob_non_spam = MLE_neg + param_non_spam\n",
    "    \n",
    "    return (prob_spam > prob_non_spam).astype('uint8')\n",
    "\n",
    "def error_rate_gaussian(data, result):\n",
    "    error_count = 0\n",
    "    \n",
    "    for count, email in enumerate(data):\n",
    "        if (classify_gaussian(email) != result[count]):\n",
    "            error_count += 1\n",
    "    return (error_count / len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16802610114192496\n",
      "0.16341145833333334\n"
     ]
    }
   ],
   "source": [
    "error_rate_gaussian_train = error_rate_gaussian(xtrain_log, ytrain)\n",
    "error_rate_gaussian_test = error_rate_gaussian(xtest_log, ytest)\n",
    "print (error_rate_gaussian_train)\n",
    "print (error_rate_gaussian_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  15,  20,  25,\n",
       "        30,  35,  40,  45,  50,  55,  60,  65,  70,  75,  80,  85,  90,\n",
       "        95, 100])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q3 Logistic Regression\n",
    "lambdas = np.hstack((np.arange(1,10,1), np.arange(10,105,5)))\n",
    "lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+exp(-x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
